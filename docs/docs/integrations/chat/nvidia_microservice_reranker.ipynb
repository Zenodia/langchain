{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fd44290d",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: NVIDIA Inference Microservice(NIM) Reranker\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e75d86",
   "metadata": {},
   "source": [
    "# NVIDIA AI Foundation Endpoints\n",
    "\n",
    "The `ChatNVIDIA` class is a LangChain chat model that connects to [NVIDIA AI Foundation Endpoints](https://www.nvidia.com/en-us/ai-data-science/foundation-models/).\n",
    "\n",
    "\n",
    "> [NVIDIA AI Foundation Endpoints](https://www.nvidia.com/en-us/ai-data-science/foundation-models/) give users easy access to NVIDIA hosted API endpoints for NVIDIA AI Foundation Models like Mixtral 8x7B, Llama 2, Stable Diffusion, etc. These models, hosted on the [NVIDIA NGC catalog](https://catalog.ngc.nvidia.com/ai-foundation-models), are optimized, tested, and hosted on the NVIDIA AI platform, making them fast and easy to evaluate, further customize, and seamlessly run at peak performance on any accelerated stack.\n",
    "> \n",
    "> With [NVIDIA AI Foundation Endpoints](https://www.nvidia.com/en-us/ai-data-science/foundation-models/), you can get quick results from a fully accelerated stack running on [NVIDIA DGX Cloud](https://www.nvidia.com/en-us/data-center/dgx-cloud/). Once customized, these models can be deployed anywhere with enterprise-grade security, stability, and support using [NVIDIA AI Enterprise](https://www.nvidia.com/en-us/data-center/products/ai-enterprise/).\n",
    "> \n",
    "> These models can be easily accessed via the [`langchain-nvidia-ai-endpoints`](https://pypi.org/project/langchain-nvidia-ai-endpoints/) package, as shown below.\n",
    "\n",
    "This example goes over how to use NVIDIA Inference Microservices (NIM)'s reranker, to spin up a reranker service as an API call( i.e obtaining an URL) , we will then combined this with NVIDIA AI Foundation endpoints' models to establish a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d1641",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The integration lives in the `langchain` package. We also need to install the `langchain-nvidia-ai-endpoints` and `faiss` package itself. We can install these with:\n",
    "\n",
    "```bash\n",
    "pip install --quiet  langchain-nvidia-ai-endpoints\n",
    "# depending the underlying compute resource, you can choose to install faiss-cpu or faiss-gpu \n",
    "pip install --quiet faiss-cpu/gpu\n",
    "```\n",
    "\n",
    "We'll also need to spin up and get an API call from [NVIDIA Inference Microservice(NIM) - Reranker ](https://nvidia-micro-service.com/) and set the `NVReranker_URL` as environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08cd30a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain-nvidia-ai-endpoints\n",
      "  Obtaining dependency information for langchain-nvidia-ai-endpoints from https://files.pythonhosted.org/packages/96/02/5abe603d4888549fa026ae58002c64f86383aa123a74513d4cf6cc945e67/langchain_nvidia_ai_endpoints-0.0.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain_nvidia_ai_endpoints-0.0.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.1 (from langchain-nvidia-ai-endpoints)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.9.1 from https://files.pythonhosted.org/packages/93/40/d3decda219ebd5410eba627601d537ec3782efbcadba308e9ce381cc0b71/aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-nvidia-ai-endpoints) (0.1.17)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.9.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (3.7.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (1.33)\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints)\n",
      "  Obtaining dependency information for langsmith<0.1,>=0.0.83 from https://files.pythonhosted.org/packages/e3/5f/739050ab18f19ad99832b290685a2e5740a05d20580d781fd3d47b1e40f8/langsmith-0.0.85-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.85-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (8.2.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (1.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (2023.7.22)\n",
      "Downloading langchain_nvidia_ai_endpoints-0.0.1-py3-none-any.whl (16 kB)\n",
      "Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.85-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m186.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: aiohttp, langsmith, langchain-nvidia-ai-endpoints\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.5\n",
      "    Uninstalling aiohttp-3.8.5:\n",
      "      Successfully uninstalled aiohttp-3.8.5\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.0.79\n",
      "    Uninstalling langsmith-0.0.79:\n",
      "      Successfully uninstalled langsmith-0.0.79\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.0.5 requires openai<2.0.0,>=1.10.0, but you have openai 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.9.3 langchain-nvidia-ai-endpoints-0.0.1 langsmith-0.0.85\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-nvidia-ai-endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65b6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"NVReranker_URL\"] = # make sure you visit xxx_url to spin up NVIDID Inference Microservice for reranker to obtain an url\n",
    "\n",
    "from langchain.retrievers.document_compressors.nim_reranker import NVRerank\n",
    "nv_rerank=NVRerank()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5910ab77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NVAPI Key (starts with nvapi-):  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "## API Key can be found by going to NVIDIA NGC -> AI Foundation Models -> (some model) -> Get API Code or similar.\n",
    "## 10K free queries to any endpoint (which is a lot actually).\n",
    "\n",
    "# del os.environ['NVIDIA_API_KEY']  ## delete key and reset\n",
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
    "else:\n",
    "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749de39c",
   "metadata": {},
   "source": [
    "It's also helpful (but not needed) to set up [LangSmith](https://smith.langchain.com/) for best-in-class observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9dc51d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'll do my best to share a joke that follows the guidelines you've provided. Here's one:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "I hope this brings a smile to your face. 😊\n"
     ]
    }
   ],
   "source": [
    "# test run and see that you can genreate a respond successfully \n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\", nvidia_api_key=nvapi_key)\n",
    "result = llm.invoke(\"tell me a joke\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "587e65a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high scoring passage: and both that morning equally lay in leaves no step had trodden black. oh, i marked the first for another day! yet knowing how way leads on to way i doubted if i should ever come back.\n",
      "low scoring passage: then took the other, as just as fair, and having perhaps the better claim because it was grassy and wanted wear, though as for that the passing there had worn them really about the same,\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "query_url=os.environ[\"NVReranker_URL\"]\n",
    "query = \"which way should i go?\"\n",
    "passages = [\n",
    "    \"two roads diverged in a yellow wood, and sorry i could not travel both and be one traveler, long i stood and looked down one as far as i could to where it bent in the undergrowth;\",\n",
    "    \"then took the other, as just as fair, and having perhaps the better claim because it was grassy and wanted wear, though as for that the passing there had worn them really about the same,\",\n",
    "    \"and both that morning equally lay in leaves no step had trodden black. oh, i marked the first for another day! yet knowing how way leads on to way i doubted if i should ever come back.\",\n",
    "    \"i shall be telling this with a sigh somewhere ages and ages hense: two roads diverged in a wood, and i, i took the one less traveled by, and that has made all the difference.\"\n",
    "]\n",
    "\n",
    "request = {\n",
    "  \"model\": \"ignored\",\n",
    "  \"query\": {\"text\": query},\n",
    "  \"passages\": [{\"text\": passage} for passage in passages]\n",
    "}\n",
    "\n",
    "response = requests.post(query_url, json=request)\n",
    "rankings = response.json()[\"rankings\"] # list of {\"index\": int, \"score\": float} with length equal to passages\n",
    "\n",
    "print(f\"high scoring passage: {passages[rankings[0]['index']]}\")\n",
    "print(f\"low scoring passage: {passages[rankings[-1]['index']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41471817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\")\n",
    "\n",
    "# Alternatively, if you want to specify whether it will use the query or passage type\n",
    "# embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\", model_type=\"passage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a5bca9",
   "metadata": {},
   "source": [
    "## Getting toy data\n",
    "\n",
    "get toy data from NVIDIA [GenerativeAIExamples](https://raw.githubusercontent.com/NVIDIA/GenerativeAIExamples/main/notebooks/toy_data/Sweden.txt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05116a1-76b5-41dd-be39-dbdab780d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/NVIDIA/GenerativeAIExamples/main/notebooks/toy_data/Sweden.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788f743c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Sweden, formally the Kingdom of Sweden, is a Nordic country located on the Scandinavian Peninsula in Northern Europe. It borders Norway to the west and north, Finland to the east, and is connected to Denmark in the southwest by a bridge–tunnel across the Öresund. At 447,425 square kilometres (172,752 sq mi), Sweden is the largest Nordic country, the third-largest country in the European Union, and the fifth-largest country in Europe. The capital and largest city is Stockholm. Sweden has a total population of 10.5 million, and a low population density of 25.5 inhabitants per square kilometre (66/sq mi), with around 87% of Swedes residing in urban areas, which cover 1.5% of the entire land area, in the central and southern half of the country.\\nNature in Sweden is dominated by forests and many lakes, including some of the largest in Europe. Many long rivers run from the Scandes range through the landscape, primarily emptying into the northern tributaries of the Baltic Sea. It has an'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "# This is a long document we can split up.\n",
    "with open(\"Sweden.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "docs = text_splitter.create_documents([state_of_the_union])\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c351d341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the Nordic and Baltic countries as well as the Baltic region as a wholePublic sectorSweden.se — Sweden's official portalThe Swedish Parliament – official websiteThe Government of Sweden – official websiteThe Royal Court Archived 11 October 2016 at the Wayback Machine – official website of the Swedish MonarchyNews mediaRadio Sweden – public serviceSveriges Television (in Swedish) – public serviceDagens Nyheter (in Swedish)Svenska Dagbladet (in Swedish)The Local – Sweden's news in English – independent English language news siteTradeWorld Bank Summary Trade Statistics SwedenTravelVisitSweden.com – official travel and tourism website for Sweden\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list_of_docs=[doc.page_content.strip().replace('\\n','') for doc in docs]\n",
    "list_of_docs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f95c413a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the vectorestore back.\n",
    "from langchain.vectorstores import FAISS\n",
    "faiss_db = FAISS.from_documents(docs,embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e4dced0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = faiss_db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75b532d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "## initialize the reranker from NVIDIA NVrerank class which is using the microservice API call\n",
    "#feed the nv_rerank into base_compressor warped in ContextualCompressionRetriever \n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=nv_rerank, base_retriever=retriever\n",
    ")\n",
    "# make a query to test\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\n",
    "    \"Did Sweden participated in World War II?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01a9dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance_score': 1.0} World War II, although its neutrality during World War II has been disputed. Sweden was under German influence for much of the war, as ties to the rest of the world were cut off through blockades. The Swedish government felt that it was in no position to openly contest Germany, and therefore made some concessions. Sweden also supplied steel and machined parts to Germany throughout the war. The Swedish government unofficially supported Finland in the Winter War and the Continuation War by allowing volunteers and materiel to be shipped to Finland. However, Sweden supported Norwegian resistance against Germany, and in 1943 helped rescue Danish Jews from deportation to Nazi concentration camps.\n",
      "During the last year of the war, Sweden began to play a role in humanitarian efforts, and many refugees, among them several thousand Jews from Nazi-occupied Europe, were rescued thanks to the Swedish rescue missions to internment camps and partly because Sweden served as a haven for refugees,\n",
      "------------------------------\n",
      "{'relevance_score': 0.5673981308937073} as the country has not been in a state of war since the end of the Swedish campaign against Norway in 1814. During World War II Sweden joined neither the allied nor axis powers. This has sometimes been disputed since in effect Sweden allowed in select cases the Nazi regime to use its railroad system to transport troops and goods, especially iron ore from mines in northern Sweden, which was vital to the German war machine. However, Sweden also indirectly contributed to the defence of Finland in the Winter War, and permitted the training of Norwegian and Danish troops in Sweden after 1943.\n",
      "\n",
      "During the early Cold War era, Sweden combined its policy of non-alignment and a low profile in international affairs with a security policy based on strong national defence. The function of the Swedish military was to deter attack. At the same time, the country maintained relatively close informal connections with the Western bloc, especially in the realm of intelligence exchange. In 1952, a Swedish\n",
      "------------------------------\n",
      "{'relevance_score': 0.0} was avoided in 1917, following the re-introduction of parliamentarism, and the country was democratised.\n",
      "\n",
      "\n",
      "=== World War I and World War II ===\n",
      "\n",
      "Sweden was officially neutral during World War I. However, under pressure from the German Empire, they did take steps which were detrimental to the Allied powers. Most notably, mining the Øresund channel, thus closing it to Allied shipping, and allowing the Germans to use Swedish facilities and the Swedish cipher to transmit secret messages to their overseas embassies. Sweden also allowed volunteers to fight for the White Guards alongside the Germans against the Red Guards and Russians in the Finnish Civil War, and briefly occupied Åland in cooperation with the German Empire.\n",
      "\n",
      "As in the First World War, Sweden remained officially neutral during World War II, although its neutrality during World War II has been disputed. Sweden was under German influence for much of the war, as ties to the rest of the world were cut off through blockades. The\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for d in compressed_docs:\n",
    "    print(d.metadata, d.page_content )\n",
    "    print('---'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6216dd1",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "You can also easily combine with a prompt template for easy structuring of user input. We can do this using [LCEL](/docs/expression_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dfb352b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sweden is a country located in northern Europe, known for its extensive forest coverage which accounts for a significant portion of its land area. The country has a varied landscape, with the highest population density found in the southern region known as the Öresund Region, along the western coast up to central Bohuslän, and in the valley of lake Mälaren and Stockholm.\\n\\nSweden is home to several large islands and lakes, with Gotland and Öland being the largest islands, and Vänern and Vättern being the largest lakes. Vänern is particularly noteworthy as it is the third largest lake in Europe, after Lake Ladoga and Lake Onega in Russia. When combined with the third- and fourth-largest lakes Mälaren and Hjälmaren, these lakes take up a significant part of southern Sweden's area.\\n\\nSweden's waterway availability is extensive, particularly in the southern part of the country. This was exploited in the 19th century with the building of the Göta Canal, which shortened the potential distance between the Baltic Sea south of Norrköping and Gothenburg by using the lake and river network to facilitate the canal.\\n\\nAdditionally, Sweden has several long rivers, particularly in the northern and central regions. These rivers, known as älvar, are commonly sourced within the Scandinavian Mountains and are a significant feature of the country's geography.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer solely based on the following context:\\n<Documents>\\n{context}\\n</Documents>\",\n",
    "        ),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": compression_retriever.get_relevant_documents, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"Tell me about Sweden's geographic information?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666bd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

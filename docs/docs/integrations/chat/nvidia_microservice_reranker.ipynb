{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fd44290d",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_label: NVIDIA Inference Microservice(NIM) Reranker\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e75d86",
   "metadata": {},
   "source": [
    "# Cohere\n",
    "\n",
    "This notebook covers how to get started with [Cohere chat models](https://cohere.com/chat).\n",
    "\n",
    "Head to the [API reference](https://api.python.langchain.com/en/latest/chat_models/langchain_community.chat_models.cohere.ChatCohere.html) for detailed documentation of all attributes and methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681d1641",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The integration lives in the `langchain` package. We also need to install the `cohere` package itself. We can install these with:\n",
    "\n",
    "```bash\n",
    "pip install --quiet  langchain-nvidia-ai-endpoints\n",
    "```\n",
    "\n",
    "We'll also need to spin up and get an API call from [NVIDIA Inference Microservice(NIM) - Reranker ](https://nvidia-micro-service.com/) and set the `NVReranker_URL` as environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08cd30a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain-nvidia-ai-endpoints\n",
      "  Downloading langchain_nvidia_ai_endpoints-0.0.1-py3-none-any.whl (16 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.9.1\n",
      "  Downloading aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: langchain-core<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-nvidia-ai-endpoints) (0.1.17)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (4.0.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.9.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain-nvidia-ai-endpoints) (23.1.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (8.2.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (6.0.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (23.2)\n",
      "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (3.7.1)\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (0.0.83)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (1.33)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (1.10.13)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (1.1.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.0->langchain-nvidia-ai-endpoints) (3.3.1)\n",
      "Installing collected packages: aiohttp, langchain-nvidia-ai-endpoints\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.6\n",
      "    Uninstalling aiohttp-3.8.6:\n",
      "      Successfully uninstalled aiohttp-3.8.6\n",
      "Successfully installed aiohttp-3.9.3 langchain-nvidia-ai-endpoints-0.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-nvidia-ai-endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c65b6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"NVReranker_URL\"] = \"http://35.232.96.106:1976/ranking\"\n",
    "\n",
    "from langchain.retrievers.document_compressors.nim_reranker import NVRerank\n",
    "nv_rerank=NVRerank()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5910ab77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NVAPI Key (starts with nvapi-):  ······································································\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "## API Key can be found by going to NVIDIA NGC -> AI Foundation Models -> (some model) -> Get API Code or similar.\n",
    "## 10K free queries to any endpoint (which is a lot actually).\n",
    "\n",
    "# del os.environ['NVIDIA_API_KEY']  ## delete key and reset\n",
    "if os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    print(\"Valid NVIDIA_API_KEY already in environment. Delete to reset\")\n",
    "else:\n",
    "    nvapi_key = getpass.getpass(\"NVAPI Key (starts with nvapi-): \")\n",
    "    assert nvapi_key.startswith(\"nvapi-\"), f\"{nvapi_key[:5]}... is not a valid key\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = nvapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749de39c",
   "metadata": {},
   "source": [
    "It's also helpful (but not needed) to set up [LangSmith](https://smith.langchain.com/) for best-in-class observability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9dc51d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'll do my best to share a light-hearted, inclusive, and fun joke with you. Here it is:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "I hope this brought a smile to your face. I'm here to ensure our conversation remains positive, respectful, and safe. If you have any questions or need assistance with a specific topic, please feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# test run and see that you can genreate a respond successfully \n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "llm = ChatNVIDIA(model=\"mixtral_8x7b\", nvidia_api_key=nvapi_key)\n",
    "result = llm.invoke(\"tell me a joke\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "587e65a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high scoring passage: and both that morning equally lay in leaves no step had trodden black. oh, i marked the first for another day! yet knowing how way leads on to way i doubted if i should ever come back.\n",
      "low scoring passage: then took the other, as just as fair, and having perhaps the better claim because it was grassy and wanted wear, though as for that the passing there had worn them really about the same,\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "query_url=os.environ[\"NVReranker_URL\"]\n",
    "query = \"which way should i go?\"\n",
    "passages = [\n",
    "    \"two roads diverged in a yellow wood, and sorry i could not travel both and be one traveler, long i stood and looked down one as far as i could to where it bent in the undergrowth;\",\n",
    "    \"then took the other, as just as fair, and having perhaps the better claim because it was grassy and wanted wear, though as for that the passing there had worn them really about the same,\",\n",
    "    \"and both that morning equally lay in leaves no step had trodden black. oh, i marked the first for another day! yet knowing how way leads on to way i doubted if i should ever come back.\",\n",
    "    \"i shall be telling this with a sigh somewhere ages and ages hense: two roads diverged in a wood, and i, i took the one less traveled by, and that has made all the difference.\"\n",
    "]\n",
    "\n",
    "request = {\n",
    "  \"model\": \"ignored\",\n",
    "  \"query\": {\"text\": query},\n",
    "  \"passages\": [{\"text\": passage} for passage in passages]\n",
    "}\n",
    "\n",
    "response = requests.post(query_url, json=request)\n",
    "rankings = response.json()[\"rankings\"] # list of {\"index\": int, \"score\": float} with length equal to passages\n",
    "\n",
    "print(f\"high scoring passage: {passages[rankings[0]['index']]}\")\n",
    "print(f\"low scoring passage: {passages[rankings[-1]['index']]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41471817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "\n",
    "embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\")\n",
    "\n",
    "# Alternatively, if you want to specify whether it will use the query or passage type\n",
    "# embedder = NVIDIAEmbeddings(model=\"nvolveqa_40k\", model_type=\"passage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a5bca9",
   "metadata": {},
   "source": [
    "## Getting toy data\n",
    "\n",
    "get toy data from NVIDIA [GenerativeAIExamples](https://raw.githubusercontent.com/NVIDIA/GenerativeAIExamples/main/notebooks/toy_data/Sweden.txt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788f743c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Sweden, formally the Kingdom of Sweden, is a Nordic country located on the Scandinavian Peninsula in Northern Europe. It borders Norway to the west and north, Finland to the east, and is connected to Denmark in the southwest by a bridge–tunnel across the Öresund. At 447,425 square kilometres (172,752 sq mi), Sweden is the largest Nordic country, the third-largest country in the European Union, and the fifth-largest country in Europe. The capital and largest city is Stockholm. Sweden has a total population of 10.5 million, and a low population density of 25.5 inhabitants per square kilometre (66/sq mi), with around 87% of Swedes residing in urban areas, which cover 1.5% of the entire land area, in the central and southern half of the country.\\nNature in Sweden is dominated by forests and many lakes, including some of the largest in Europe. Many long rivers run from the Scandes range through the landscape, primarily emptying into the northern tributaries of the Baltic Sea. It has an'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "# This is a long document we can split up.\n",
    "with open(\"Sweden.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "docs = text_splitter.create_documents([state_of_the_union])\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c351d341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the Nordic and Baltic countries as well as the Baltic region as a wholePublic sectorSweden.se — Sweden's official portalThe Swedish Parliament – official websiteThe Government of Sweden – official websiteThe Royal Court Archived 11 October 2016 at the Wayback Machine – official website of the Swedish MonarchyNews mediaRadio Sweden – public serviceSveriges Television (in Swedish) – public serviceDagens Nyheter (in Swedish)Svenska Dagbladet (in Swedish)The Local – Sweden's news in English – independent English language news siteTradeWorld Bank Summary Trade Statistics SwedenTravelVisitSweden.com – official travel and tourism website for Sweden\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list_of_docs=[doc.page_content.strip().replace('\\n','') for doc in docs]\n",
    "list_of_docs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f95c413a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the vectorestore back.\n",
    "from langchain.vectorstores import FAISS\n",
    "faiss_db = FAISS.from_documents(docs,embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e4dced0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = faiss_db.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75b532d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "## initialize the reranker from NVIDIA NVrerank class which is using the microservice API call\n",
    "#feed the nv_rerank into base_compressor warped in ContextualCompressionRetriever \n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=nv_rerank, base_retriever=retriever\n",
    ")\n",
    "# make a query to test\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\n",
    "    \"Did Sweden participated in World War II?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01a9dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance_score': 1.0} World War II, although its neutrality during World War II has been disputed. Sweden was under German influence for much of the war, as ties to the rest of the world were cut off through blockades. The Swedish government felt that it was in no position to openly contest Germany, and therefore made some concessions. Sweden also supplied steel and machined parts to Germany throughout the war. The Swedish government unofficially supported Finland in the Winter War and the Continuation War by allowing volunteers and materiel to be shipped to Finland. However, Sweden supported Norwegian resistance against Germany, and in 1943 helped rescue Danish Jews from deportation to Nazi concentration camps.\n",
      "During the last year of the war, Sweden began to play a role in humanitarian efforts, and many refugees, among them several thousand Jews from Nazi-occupied Europe, were rescued thanks to the Swedish rescue missions to internment camps and partly because Sweden served as a haven for refugees,\n",
      "------------------------------\n",
      "{'relevance_score': 0.5673981308937073} as the country has not been in a state of war since the end of the Swedish campaign against Norway in 1814. During World War II Sweden joined neither the allied nor axis powers. This has sometimes been disputed since in effect Sweden allowed in select cases the Nazi regime to use its railroad system to transport troops and goods, especially iron ore from mines in northern Sweden, which was vital to the German war machine. However, Sweden also indirectly contributed to the defence of Finland in the Winter War, and permitted the training of Norwegian and Danish troops in Sweden after 1943.\n",
      "\n",
      "During the early Cold War era, Sweden combined its policy of non-alignment and a low profile in international affairs with a security policy based on strong national defence. The function of the Swedish military was to deter attack. At the same time, the country maintained relatively close informal connections with the Western bloc, especially in the realm of intelligence exchange. In 1952, a Swedish\n",
      "------------------------------\n",
      "{'relevance_score': 0.0} was avoided in 1917, following the re-introduction of parliamentarism, and the country was democratised.\n",
      "\n",
      "\n",
      "=== World War I and World War II ===\n",
      "\n",
      "Sweden was officially neutral during World War I. However, under pressure from the German Empire, they did take steps which were detrimental to the Allied powers. Most notably, mining the Øresund channel, thus closing it to Allied shipping, and allowing the Germans to use Swedish facilities and the Swedish cipher to transmit secret messages to their overseas embassies. Sweden also allowed volunteers to fight for the White Guards alongside the Germans against the Red Guards and Russians in the Finnish Civil War, and briefly occupied Åland in cooperation with the German Empire.\n",
      "\n",
      "As in the First World War, Sweden remained officially neutral during World War II, although its neutrality during World War II has been disputed. Sweden was under German influence for much of the war, as ties to the rest of the world were cut off through blockades. The\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for d in compressed_docs:\n",
    "    print(d.metadata, d.page_content )\n",
    "    print('---'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6216dd1",
   "metadata": {},
   "source": [
    "## Chaining\n",
    "\n",
    "You can also easily combine with a prompt template for easy structuring of user input. We can do this using [LCEL](/docs/expression_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dfb352b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sweden is a country located in northern Europe, known for its extensive forest coverage which accounts for a significant portion of its land area. The country has a varied landscape, with the highest population density found in the southern region known as the Öresund Region, along the western coast up to central Bohuslän, and in the valley of lake Mälaren and Stockholm.\\n\\nSweden is home to several large islands and lakes, with Gotland and Öland being the largest islands, and Vänern and Vättern being the largest lakes. Vänern is the third largest lake in Europe, after Lake Ladoga and Lake Onega in Russia. When combined with the third- and fourth-largest lakes Mälaren and Hjälmaren, these lakes take up a significant part of southern Sweden's area.\\n\\nSweden's waterway availability throughout the south was exploited with the building of the Göta Canal in the 19th century, which shortened the potential distance between the Baltic Sea south of Norrköping and Gothenburg by using the lake and river network to facilitate the canal. The country also has several long rivers, particularly in Northern and Central Sweden, which are commonly sourced within the Scandinavian Mountains and are known as älvar. The longest of these rivers is the Klarälven, which spans 460 kilometers.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer solely based on the following context:\\n<Documents>\\n{context}\\n</Documents>\",\n",
    "        ),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": compression_retriever.get_relevant_documents, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"Tell me about Sweden's geographic information?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666bd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
